{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/Sarthakischauhan/nst-cs152/blob/main/server/nst_first.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Attention, below implementation deprecated.\n",
    "\n",
    "As mentioned, I am now using the tensorflow model so this file is not in use. Will come back here later. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "id": "ohE3DixJzeZX",
    "outputId": "1194ebea-0131-4a37-b32c-88ce4a4caaed"
   },
   "outputs": [],
   "source": [
    "%pip install flask-ngrok\n",
    "from flask import Flask, request, jsonify, send_file\n",
    "from flask_ngrok import run_with_ngrok\n",
    "import os\n",
    "import torch\n",
    "from torchvision import models, transforms\n",
    "from PIL import Image\n",
    "import io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "DuYxhxkBBQOn"
   },
   "outputs": [],
   "source": [
    "# We don't want to run cuda binaries if our current device is not cuda capable.\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "V7zA7O9e2FWr"
   },
   "source": [
    "Flask app to create API for Neural Style Transfer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "mUysSryg0yhs"
   },
   "outputs": [],
   "source": [
    "app = Flask(__name__)\n",
    "run_with_ngrok(app)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "q1GbPJnB2Ctg"
   },
   "outputs": [],
   "source": [
    "def image_loader(image_bytes, device, max_size=400):\n",
    "    image = Image.open(io.BytesIO(image_bytes)).convert('RGB')\n",
    "    size = max_size if max(image.size) > max_size else max(image.size)\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize(size),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "    ])\n",
    "    image = transform(image).unsqueeze(0)\n",
    "    return image.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Edd4CHO43HoO"
   },
   "source": [
    "Load our VGG model in the pretrained mode.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VMwEjknX2ybp"
   },
   "outputs": [],
   "source": [
    "vgg = models.vgg19(pretrained=True).features.to(device).eval()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyMcn+kxJJDZ/U5JJtnfugrO",
   "include_colab_link": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
